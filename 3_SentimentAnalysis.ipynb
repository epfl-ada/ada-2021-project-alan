{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. SentimentAnalysis.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Contents\n","3. [Sentiment Analysis](#3.-Sentiment-Analysis)  \n","    3.1. [Merge years](#3.1.-Merge-years)   \n","    3.2. [Sentiment analysis](#3.2.-Sentiment-analysis)"],"metadata":{"id":"8AtvAtEK4LTs"}},{"cell_type":"markdown","source":["# **3. Sentiment Analysis**"],"metadata":{"id":"63Y3I9XI04PI"}},{"cell_type":"markdown","source":["The goal of sentiment analysis is to associate an opinion to each quote belonging to a certain topic. To quantify the opinion of a quote, we use Sentiment Analysis, a technique in natural language processing that links a sentiment score to a text. The sentiment or *polarity score* is a scalar between -1 and 1, where **-1 reflects a strongly negative sentiment, 1 strongly positive and 0 a neutral opinion**. \n","\n","After a comparison with Flair and TextBlob (cf. `Milestone2/SentimentAnalysis_exploration`), we decided to use for this scope **VADER**, a rule-based (bag of words) sentiment analysis tool developed at MIT specifically attuned to sentiments expressed in social media. In brief, VADER links a sentiment score to each individual word in a sentence, and calculates the final sentiment score as the mean of each individual word in the sentence [[1]](https://ojs.aaai.org/index.php/ICWSM/article/view/14550).  "],"metadata":{"id":"L9pdqprH07vp"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkbVzyku4OS6","executionInfo":{"status":"ok","timestamp":1639584048630,"user_tz":-60,"elapsed":18089,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}},"outputId":"7cb562e7-fe95-4ffb-9f70-9e46e3d04e97"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive._mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0ZcWm1KVCqP","executionInfo":{"status":"ok","timestamp":1639584076664,"user_tz":-60,"elapsed":7122,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}},"outputId":"dc49fbfe-1709-4e8b-bad2-b1ea8bcb3073"},"source":["!pip install vaderSentiment\n","!pip install fastparquet"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n","Requirement already satisfied: fastparquet in /usr/local/lib/python3.7/dist-packages (0.7.2)\n","Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (0.15.0)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.19.5)\n","Requirement already satisfied: cramjam>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (2.5.0)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from fastparquet) (2021.11.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->fastparquet) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"WiOAFwP_4NWi","executionInfo":{"status":"ok","timestamp":1639584645723,"user_tz":-60,"elapsed":871,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pyarrow.parquet as pq\n","import pyarrow as pa\n","import time"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sU9J_wvU_io","executionInfo":{"status":"ok","timestamp":1639584649674,"user_tz":-60,"elapsed":2217,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}},"outputId":"c7857306-7b93-407c-ac8d-c7d4c2f5434e"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"]}]},{"cell_type":"code","metadata":{"id":"zS0C5LmY4S6O","executionInfo":{"status":"ok","timestamp":1639584649675,"user_tz":-60,"elapsed":7,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["preprocess_folder = '/content/drive/MyDrive/ADA/Processed/'\n","sentiment_folder = '/content/drive/MyDrive/ADA/Sentiment/'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"a26e7vDc4Zew","executionInfo":{"status":"ok","timestamp":1639584650657,"user_tz":-60,"elapsed":3,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["import datetime\n","import pytz\n","def printts(*objects):\n","    print(datetime.datetime.now(pytz.timezone('Europe/Zurich')).strftime(\"%d %b %Y %H:%M:%S\"), \":\", *objects)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iSO1fwPHgZ0i"},"source":["## 3.1. Merge years"]},{"cell_type":"code","metadata":{"id":"p05MMV6EgZPZ","executionInfo":{"status":"ok","timestamp":1639584756102,"user_tz":-60,"elapsed":292,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["def merge_df():\n","  '''\n","  Loads the preprocessed DataFrame for each year from 2015 to 2020 and merge them\n","  in a unique DataFrame.\n","  '''\n","\n","  # Create list of preprocessed DataFrames per year\n","  df_years = []\n","  for filename in sorted(os.listdir(preprocess_folder), reverse=True):\n","    processpath = os.path.join(preprocess_folder, filename)\n","    printts(f'Reading {filename}...')\n","    df_year = pd.read_parquet(processpath)\n","    df_years.append(df_year)\n","\n","  # Concatenate the processed years into one single dataframe\n","  printts(f'Combining years...')\n","  df = pd.concat(df_years)\n","  del df_year\n","  del df_years\n","\n","  # Shuffle dataframe\n","  df = df.sample(frac=1, random_state=42)\n","\n","  # Set index\n","  index = np.array(list(map(lambda x: 'q' + x, np.arange(len(df)).astype(str))))\n","  df = df.set_index(index)\n","  # df = df.reset_index(drop=True)\n","\n","  printts('Merging done')\n","  return df"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAzH5uj3gQ33"},"source":["## 3.2. Sentiment analysis"]},{"cell_type":"code","metadata":{"id":"0PsDnmsggUc8","executionInfo":{"status":"ok","timestamp":1639584802091,"user_tz":-60,"elapsed":207,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["# Create the VADER analyzer\n","analyzer = SentimentIntensityAnalyzer()\n","\n","def get_vader_compound_score(sentence):\n","  # Apply VADER analyzer and get compound score\n","  return analyzer.polarity_scores(sentence)['compound']"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t24UmVwukxMz","executionInfo":{"status":"ok","timestamp":1638975857342,"user_tz":-60,"elapsed":134663,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}},"outputId":"657de5d7-e60d-44a0-c4b8-b61107c2cfbc"},"source":["df = merge_df()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["08 Dec 2021 16:02:01 : Reading quotes-2020.parquet.gzip...\n","08 Dec 2021 16:02:05 : Reading quotes-2019.parquet.gzip...\n","08 Dec 2021 16:02:19 : Reading quotes-2018.parquet.gzip...\n","08 Dec 2021 16:02:43 : Reading quotes-2017.parquet.gzip...\n","08 Dec 2021 16:03:09 : Reading quotes-2016.parquet.gzip...\n","08 Dec 2021 16:03:20 : Reading quotes-2015.parquet.gzip...\n","08 Dec 2021 16:03:33 : Combining years...\n","08 Dec 2021 16:04:15 : Merging done\n"]}]},{"cell_type":"markdown","source":["For convenience, we will again process our filtered DataFrame in chunks."],"metadata":{"id":"D8qbm_xm4Bs0"}},{"cell_type":"code","metadata":{"id":"JhW_lu8MwhH1","executionInfo":{"status":"ok","timestamp":1639584889226,"user_tz":-60,"elapsed":218,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}}},"source":["def process_chunk(chunk, rpath):\n","  '''\n","  Compute the sentiment for each quote in the chunk.\n","  '''\n","  printts('Predicting VADER compound scores ...')\n","  chunk['sentiment'] = chunk.quotation.apply(get_vader_compound_score)\n","\n","  # Create a parquet table from your dataframe\n","  table = pa.Table.from_pandas(chunk[['sentiment']])\n","\n","  # Write the table to our parquet file.\n","  # To append to an existing file, we need to use pyarrow.parquet here\n","  printts(f'Writing chunk to {rpath}...')\n","  pq.write_to_dataset(table, compression='gzip', root_path=rpath)\n","  printts('Writing done')\n","  print('-------------------------')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKldlm2cw0tW","executionInfo":{"status":"ok","timestamp":1639584796503,"user_tz":-60,"elapsed":225,"user":{"displayName":"Francesco Salvi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17039456355099176000"}},"outputId":"2ec63aac-8f7d-48c4-db8b-12452ba0aa00"},"source":["df_path = os.path.join(sentiment_folder, 'df_politicians_sentiment_only.parquet.gzip')\n","chunksize = 1e6\n","\n","if(not os.path.exists(df_path)):\n","  indx = np.concatenate([np.arange(0, len(df), chunksize), [len(df)]]).astype('int')\n","  for ii in range(0, len(indx)-1):\n","    chunk = df.iloc[indx[ii]:indx[ii+1]]\n","    process_chunk(chunk, df_path)\n","else:\n","  print('Found file ' + df_path)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found file /content/drive/MyDrive/ADA/Sentiment/df_politicians_sentiment_only.parquet.gzip\n"]}]}]}